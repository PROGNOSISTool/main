\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{bbm}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\B}{\mathbb{B}}
\usetikzlibrary{shapes,arrows}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}

\newcommand{\lang}[1]{\mathcal{L}(#1)}


%%Macros%% 
\newcommand\adapter{\textbf{Adapter}\xspace}
\newcommand\mapper{\textbf{Mapper}\xspace}
\newcommand\implementation{\textbf{Implementation}\xspace}
\newcommand\sul{\textbf{SUL}\xspace}
\newcommand\at{\textbf{Abstraction Table}\xspace}


\begin{document}

\section{Introduction}
\textbf{TODO}: List changes to RFC, differences found between implementations.
\textbf{TODO}: Mention issue found in reference implementation used for adapter where new connections after retry did not re-use the same port, leading to connection failure with MSQUIC.

\section{Example}

\input{setup}

\section{Problem definition}


\subsection{$w$-machines}
\input{model.tex}

\begin{definition}[Problem Definition]
Assume we have a system under learning, which can be described with a $w$-machine $W$. Furthermore assume we have an oracle for the system under learning $O : I^* \to \{\top, \bot\}$, such that the oracle decides membership in $W$ (i.e. $\lambda w. w \in \mathcal{L}(W) = O$). We wish to recreate the $w$-machine with the oracle.
\end{definition}

\section{Learning w-machines}

In this section, we present the algorithm for learning w-machines from the oracle.
First we show how the alphabets involved in the learning problem can be abstracted to learn a finite state machine
without counters in Section~\ref{}. Second, we present an algorithm that given an abstract finite state machine
and the corresponding set of concrete examples generalizes the finite state machine to a w-machine that is consistent
with the concrete examples and it uses counters in Section~\ref{}.

\subsection{Learning abstract w-machines}


\begin{definition}
An abstraction function $\alpha : (\Sigma \times \Gamma) \to (\hat\Sigma \times \hat\Gamma)$ maps alphabets $\Sigma$ and $\Gamma$ to finite alphabets $\hat\Sigma$ and $\hat\Gamma$, respectively.
\end{definition}
Note: maybe gamma doesn't need to be finite. Investigate

\begin{example}
TODO show example of alpha using example in sec 2
\end{example}

\begin{definition}[Abstract w-machine]
An Abstract $w$-machine $M_\alpha$ is a 6-tuple $(S, S_0, \hat\Sigma, \hat\Lambda, T, G)$, such that:
\begin{itemize}
    \item $S$ is a finite set of states. 
    \item $S_0$ is the initial state such that $S_0 \in S$.
    \item $\hat\Sigma$ is the abstract input alphabet. 
    \item $\hat\Gamma$ is the abstract output alphabet.
    \item $T$ is the transition function $T \colon S \times \hat\Sigma \to S$.
    \item $G$ is the output function $G \colon S \times \hat\Sigma \to \hat\Gamma$.
\end{itemize}
\end{definition}

\begin{definition}[Abstracting a w-machine]
Given an abstraction function $\alpha$ from $(\Sigma,\Gamma)$ to $(\hat\Sigma,\hat\Gamma)$,
and a w-machine $M=(I, O, R, r_0, Q, q_0, \Delta, F)$
the abstract w-machine $M_\alpha=(S, S_0, \hat\Sigma, \hat\Gamma, T, G)$.
\end{definition}

Something about $M_\alpha$ simulating $M$.

Using this, we can now try to learn $M_\alpha$, but to do so we need an oracle for it.

Explain how to get abstract membership queries from the oracle you have.
\begin{theorem}
We will  learn the abstract w-machine for the given machine using the oracle
\end{theorem}


Note that an abstract w-machine is equivalent to a classic mealy machine, which we can learn using existing algorithms.

\subsection{Learner interface}
Our learning process starts with the classic \emph{Minimally Adequate Teacher} (MAT) framework. We have a learner that is attempting to infer a model Abstract $w$-machine via two kinds of queries:
\begin{itemize}
    \item \textbf{Membership Queries} of the type $w_O = mq(w_I)$ where $w_I \in \hat\Sigma^+$ and $w_O \in \hat\Gamma^+$. In practise, these are single $w_I / w_O$ traces of the system that allow the learner to acquire knowledge about the behaviour of the SUL so that it can build an hypothesis model $H$.
    \item \textbf{Equivalence Queries} of the type $w_I / w_O = eq(H)$ where $H$ is an hypothesis model the learner believes to be correct and wants to know if it is indeed equivalent to the SUL, the answer $c$ is a counterexample trace that is present in the SUL, but not in the hypothesis model $H$, thus proving the hypothesis is not correct. If no counterexample is returned, theoretically the model is equivalent to the system, and thus correct. In practice, Equivalence Queries would require an Equivalence Oracle omniscient of the SUL, and if we had that, we wouldn't have to learn the system in the first place. However, we can use heuristic Equivalence Oracles such that when a counterexample is returned, it is indeed guaranteed to be a valid counterexample, but the absence of a counterexample no longer guarantees equivalence. This can still give us PAC guarantees.
\end{itemize}

With oracles capable of answering the two types of queries mentioned above, we are able to make use of a black-box learning algorithm to learn a model of the SUL. There are many different algorithms that can learn a model with access to these oracles using different backing data structures and with different efficiencies, however they almost always follow a similar loop based structure as such:

\textbf{TODO}: Make sure this makes sense for at least both L* and TTT.

\begin{algorithm}[H]
\KwResult{Learned Model}
L := Learner($\hat\Sigma$)\;
\While{True}{
    $W_I$ := L.buildQueries()\;
    \If{$W_I$ = $\O$ }{
        H := L.hypothesis()\;
        \If{$w_I / w_O$ := eq(H)}{
            L.consider($w_I / w_O$)\;
            continue\;
        }
        \Return{H}\;
    }
    \For{$w_I \in W$}{
        $w_O$ := mq($w_I$)\;
        L.consider($w_I / w_O$)\;
    }
}
\caption{Black-box learning loop}
\end{algorithm}

\subsection{Generalizing abstract w-machines to w-machines}
We have now successfully learned an Abstract $w$-machine through the abstraction alphabets $\hat\Sigma$ and $\hat\Gamma$, however we still want to enrich this model by generalising it to a $w$-machine.

\begin{definition}[$w$-machine SMT problem]
$w$-machine SMT problem is given by the function 
$$\mathcal{S} : (A \times E \times [0, K) \times [0, R) \times C) \to \{\bot\} \sqcup (2^{Q \times Q \times [0, K) \times O \times \{\phi, \chi, \psi\}}, [0, R) \to \mathbb{Z})$$
Where:
\begin{itemize}
    \item $A$ is the finite automata learned in the previous
    \item $E$ is the set of examples and counter-examples given
    \item $K$ is the number of edges between any two states
    \item $R$ is the number of registers to assume for synthesis
    \item $C$ is the set of constants
    \item $Q$ is the set of states of $A$
    \item $O$ is the set of operators given in $H(P,Q)$ in the guard definition
    \item $\phi$, $\chi$, and $\psi$ are just labels.
\end{itemize}
It asks to find a subset $I$ of $Q \times Q \times K \times O \times \{\phi, \chi, \psi\}$,
and initial register assignment $D: [0, R) \to \mathbb{Z}$,
such that an edge between two nodes in $A$ with label $f$
is necessary and sufficient between two nodes in the synthesized machine with requirement that label $f$ also be matched by the input. 
If it can't, it returns $\bot$: failure.
This can be written as a very large SMT problem.
\textbf{TODO: probably not, but maybe put problem in?}
\end{definition}

The idea is we enrich the learned automata with extra information along the edges that can use registers to match extra information of the language (information that can not be represented with a finite state machine).

\subsection{How to generalize abstract w-machines to w-machines}
\begin{algorithm}[H]
\caption{synthesis algorithm}
\For{$e, r, c \in \N^3$, diagonally}{
    $v \gets S(A, examples, e, r, c)$\;
    \If{$v = \bot$}{
        \textbf{continue}\;
    } \Else{
        $m \gets$ machine gathered from $v$\;
        \For{$(i, o) \in \lang{m} \cup \lang{\neg m}$}{
            \If{$(i, o) \in \lang{m} \wedge (i, o) \not\in \lang{s}$}{ \tcp*{$s$ is the system under learning}
                add $\neg(i, o)$ to $examples$ \tcp*{that is, as a counter example}
                \textbf{break}\;
            } 
            \If{$(i, o) \not\in \lang{m} \wedge (i, o) \in \lang{s}$}{
                add $(i, o)$ to $examples$\;
                \textbf{break}\;
            }
        }
    }
}
\end{algorithm}

Soundness theorem: the synthesize machine will always be correct upto all examples seen

% This is pretty straight forward: we require in SMT problem all examples are right and that the abstract automata is right

Completeness theorem: If your automata can be represented by abstracted 
to a learnable automata, then your automata can be synthesized using a learned automata to define its structure. 

\subsubsection{Proof of completeness}

\begin{lemma}[The right NFA from a DFA]
We can synthesize $M$, an $NFA$,
over a finite alphabet $\alpha$ upto state-isomorphism using $1$ register and $|M|$ edges.
\end{lemma}

Suppose we are synthesizing a big-counter machine $A$ also over $\alpha$ starting with a graph structure given by a DFA representation of $M$, called $B$, that has an isomorphism between states of $M$ and states and registers of $A$.
Let the states of the machines be given by $Q_M$ and $Q_A$ respectively, and the same with $\Delta_M$ and $\Delta_A$.
Assume any mapping from $Z : Q_M \to \mathbb{Z}$.
Assume, further a mapping from $D : Q_m \to 2^{Q_a}$, which takes a $q \in Q_m$ to a subset states $q_a$ of $Q_a$ such that there exists a string $s$ where $M[s] = q$, and $q_a = B[s]$.
Then, we can map each state $m$ in $M$ to a register value $R(m)$,
and each edge $(q_m, c, p_m)$to a set of $w$-machine edges: $\{(q_a, c \wedge r = Zq, p_a) : p_a \in Dp_m, q_a \in Dq_m\}$.
Thus if we are in state $q_a$ and register value $r$, with input $c$, we will go state $p_a$ and register value $r'$ if there is an edge $(Dr, c, Dr')$ in $M$, and same visa versa. $\square$ 

Assuming we can do the above, then we can learn all additional data across the edges with $r+1$ registers and $|S|$ states, where $r$ is the number of registers used by the machine $S$.

Furthermore, there are finite machines for every given number of registers and states (essentially powerset over relations including bit-vector values, product of this over three predicates, is big but finite). As we will eventually always get each trace, we will eventually get a set of traces that shatters the set of machines down to just one machine. 

\subsubsection{Proof of Soundness}

Positive examples are only added if they are actually generated by the system under learning.
Negative examples are only tentatively added, so that if they are seen later, those negative example are added.
Thus, we only synthesize machines that behave correctly according to all examples we've seen,
and if we assume a negative example, and we  ever learn that is accepted, then we remove it. 

% It got a little late to type this out, but this requires two parts, first we show that we learn a DFA abstract mealy machine, and two that through registers and edges we can simulate what ever the orginal DFA was. So, eventually we'll synthesize the right machine

\section{Experiments}
Examples of research questions regarding the usefulness and power of this learning method. 
\begin{itemize}
    \item RQ1: Can we learn a $w$-machine that cannot be learned as a regular machine?
    \item RQ2: Can we extract useful specification properties from this machine?
    \item RQ3: Can we learn a $w$-machine using only the queries used in learning the abstract $w$-machine?
\end{itemize}

To evaluate these questions, we use our learning technique to model check implementations of the QUIC Protocol. QUIC is a new general-purpose transport layer network protocol that aims to improve connections by decreasing the amount of handshakes required for different protocol layers, eliminating head-of-line blocking, and allowing for connection recovery even when the client changes networks. QUIC enables all this while providing packet encryption at the transport layer. 

One can picture QUIC as a \emph{super protocol}, as it eliminates the needs for so many other network layers by incorporating TLS1.3 in the packet encryption, and providing NAT rebinding resilience. As such, the QUIC Protocol carries an unusually high degree of complexity while having the goal of, with time, being the \emph{de-facto} standard for HTTP connections. This makes it an ideal candidate for verification. 

In this paper we will be verifying two main implementations of the IETF QUIC Protocol (Draft 29):
\begin{itemize}
    \item \textbf{Quiche}: Cloudflare's QUIC Implementation that allows QUIC connections to any website protected by Cloudflare network. QUIC support has been enabled automatically for Cloudflare-backed websites, with website administrators having the option of manually disabling it. Cloudflare's CDN supports over 25 million websites, so we believe it is crucial for this implementation to be as correct as possible.
    \item \textbf{Google QUIC}: Google's QUIC Implementation that runs on Google servers and on Chromium browsers. Since October 7 of 2020, 25\% of Google Chrome users had QUIC support enabled by default, with that proportion increasing over the followed weeks. As Google Chrome is the most widely used web browser in the world, we consider the correctness of this implementation to be crucial too.
\end{itemize}

To evaluate the correctness of these implementations we selected a subset of properties from the specification to be verified:

\begin{enumerate}
    \item An endpoint MUST open streams of the same type in increasing order of stream ID.
    \item Before a stream is created, all streams of the same type with lower- numbered stream IDs MUST be created.
    \item A sender MUST ignore any MAX\_STREAM\_DATA or MAX\_DATA frames that do not increase flow control limits.
    \item An endpoint MUST NOT send data on a stream at or beyond the final size.
    \item A receiver MUST ignore any MAX\_STREAMS frame that does not increase the stream limit.
    \item The sequence number on each newly-issued connection ID MUST increase by 1.
    \item A server MUST set the Destination Connection ID it uses for sending packets based on the first received Initial packet.
    \item A QUIC endpoint MUST NOT reuse a packet number within the same packet number space in one connection.
    \item ACK Frames and Packet Protection ACK frames MUST only be carried in a packet that has the same packet number space as the packet being ACKed.
    \item A server MUST treat receipt of a HANDSHAKE\_DONE frame as a connection error of type PROTOCOL\_VIOLATION.
\end{enumerate}


\pagebreak
\section{OLD Problem definition (deprecated below here:}

TODO: preface this all section with an intuition of what we are about to read in English

\subsection{Automata}
\input{automata}
\subsection{Big Counter Automata}
\input{bcautomata}
\subsection{Approximation}
\input{approximation}
%\input{workflow}
%\input{overview_algorithm}
\subsection{Learning}
\input{Learning}

\end{document}
